{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2247,"status":"ok","timestamp":1625222867027,"user":{"displayName":"Khoa Nguyen Van","photoUrl":"","userId":"04237962560197153587"},"user_tz":-420},"id":"Zb3HX32305lb","outputId":"a1ec6b01-6441-4ebb-a36a-9339e481d214"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1dl8_-ZeDGCZdyeGSlZYzmy_dxqXTh_rA\n","To: /content/main.py\n","\r  0% 0.00/5.97k [00:00\u003c?, ?B/s]\r100% 5.97k/5.97k [00:00\u003c00:00, 5.15MB/s]\n"]}],"source":["!gdown --id 1dl8_-ZeDGCZdyeGSlZYzmy_dxqXTh_rA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1656929,"status":"ok","timestamp":1625227044109,"user":{"displayName":"Khoa Nguyen Van","photoUrl":"","userId":"04237962560197153587"},"user_tz":-420},"id":"zpc2Rl7K1N1b","outputId":"0285c947-5119-4e62-ccb4-97e3de5a5e4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","epoch: 1 | Loss: 1.5015467335196102 | Train_acc: 28.75%| Test_acc: 25.0%\n","epoch: 2 | Loss: 1.076483342043884 | Train_acc: 27.5%| Test_acc: 31.25%\n","epoch: 3 | Loss: 0.8780818901708364 | Train_acc: 27.5%| Test_acc: 25.0%\n","epoch: 4 | Loss: 0.7704707563990523 | Train_acc: 32.5%| Test_acc: 37.5%\n","epoch: 5 | Loss: 0.6989285921501687 | Train_acc: 32.5%| Test_acc: 43.75%\n","epoch: 6 | Loss: 0.6465496288998352 | Train_acc: 37.5%| Test_acc: 37.5%\n","epoch: 7 | Loss: 0.6081392194913782 | Train_acc: 51.25%| Test_acc: 62.5%\n","epoch: 8 | Loss: 0.5750553825169878 | Train_acc: 38.75%| Test_acc: 56.25%\n","epoch: 9 | Loss: 0.5459183050543451 | Train_acc: 53.75%| Test_acc: 43.75%\n","epoch: 10 | Loss: 0.5217715068089078 | Train_acc: 50.0%| Test_acc: 50.0%\n","epoch: 11 | Loss: 0.49893277388094637 | Train_acc: 48.75%| Test_acc: 43.75%\n","epoch: 12 | Loss: 0.48686735480642684 | Train_acc: 58.75%| Test_acc: 62.5%\n","epoch: 13 | Loss: 0.4700365289855186 | Train_acc: 46.25%| Test_acc: 43.75%\n","epoch: 14 | Loss: 0.45235979297886725 | Train_acc: 56.25%| Test_acc: 43.75%\n","epoch: 15 | Loss: 0.4410109205547806 | Train_acc: 63.75%| Test_acc: 43.75%\n","epoch: 16 | Loss: 0.4308425927406077 | Train_acc: 56.25%| Test_acc: 62.5%\n","epoch: 17 | Loss: 0.41903384449079517 | Train_acc: 57.5%| Test_acc: 50.0%\n","epoch: 18 | Loss: 0.3848489785895628 | Train_acc: 55.0%| Test_acc: 56.25%\n","epoch: 19 | Loss: 0.3738824170644936 | Train_acc: 71.25%| Test_acc: 62.5%\n","epoch: 20 | Loss: 0.36408236447502584 | Train_acc: 67.5%| Test_acc: 50.0%\n","epoch: 21 | Loss: 0.35807395328188796 | Train_acc: 68.75%| Test_acc: 50.0%\n","epoch: 22 | Loss: 0.352761542934286 | Train_acc: 60.0%| Test_acc: 56.25%\n","epoch: 23 | Loss: 0.3491631548118104 | Train_acc: 70.0%| Test_acc: 68.75%\n","epoch: 24 | Loss: 0.3404512253716169 | Train_acc: 66.25%| Test_acc: 56.25%\n","epoch: 25 | Loss: 0.3411112555381282 | Train_acc: 55.0%| Test_acc: 50.0%\n","epoch: 26 | Loss: 0.3311669178249891 | Train_acc: 67.5%| Test_acc: 62.5%\n","epoch: 27 | Loss: 0.3285650437140404 | Train_acc: 63.75%| Test_acc: 56.25%\n","epoch: 28 | Loss: 0.3229409782096858 | Train_acc: 73.75%| Test_acc: 62.5%\n","epoch: 29 | Loss: 0.3173554570359342 | Train_acc: 75.0%| Test_acc: 50.0%\n","epoch: 30 | Loss: 0.31730670419038104 | Train_acc: 75.0%| Test_acc: 56.25%\n","epoch: 31 | Loss: 0.30879807411252386 | Train_acc: 71.25%| Test_acc: 62.5%\n","epoch: 32 | Loss: 0.30448558423525235 | Train_acc: 60.0%| Test_acc: 62.5%\n","epoch: 33 | Loss: 0.3051908553561286 | Train_acc: 61.25%| Test_acc: 56.25%\n","epoch: 34 | Loss: 0.30011778181928506 | Train_acc: 67.5%| Test_acc: 56.25%\n","epoch: 35 | Loss: 0.2990880796823965 | Train_acc: 67.5%| Test_acc: 68.75%\n","epoch: 36 | Loss: 0.29956250125184997 | Train_acc: 65.0%| Test_acc: 56.25%\n","epoch: 37 | Loss: 0.2922991539358788 | Train_acc: 55.0%| Test_acc: 68.75%\n","epoch: 38 | Loss: 0.29678866179550395 | Train_acc: 67.5%| Test_acc: 62.5%\n","epoch: 39 | Loss: 0.28688170640822264 | Train_acc: 65.0%| Test_acc: 56.25%\n","epoch: 40 | Loss: 0.28086042510883885 | Train_acc: 60.0%| Test_acc: 56.25%\n","epoch: 41 | Loss: 0.28182326247701256 | Train_acc: 62.5%| Test_acc: 75.0%\n","epoch: 42 | Loss: 0.28028309699671955 | Train_acc: 71.25%| Test_acc: 50.0%\n","epoch: 43 | Loss: 0.28124917649170933 | Train_acc: 61.25%| Test_acc: 56.25%\n","epoch: 44 | Loss: 0.2757991344270194 | Train_acc: 61.25%| Test_acc: 56.25%\n","epoch: 45 | Loss: 0.27848294924211014 | Train_acc: 60.0%| Test_acc: 50.0%\n","epoch: 46 | Loss: 0.26883704373446266 | Train_acc: 63.75%| Test_acc: 62.5%\n","epoch: 47 | Loss: 0.27234414181745875 | Train_acc: 68.75%| Test_acc: 50.0%\n","epoch: 48 | Loss: 0.2695864422623154 | Train_acc: 63.75%| Test_acc: 50.0%\n","epoch: 49 | Loss: 0.265575199518972 | Train_acc: 63.75%| Test_acc: 43.75%\n","epoch: 50 | Loss: 0.2667347911716727 | Train_acc: 57.5%| Test_acc: 56.25%\n","==\u003e Finished Training ...\n"]}],"source":["# adam\n","!python main.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1656335,"status":"ok","timestamp":1625231754281,"user":{"displayName":"Khoa Nguyen Van","photoUrl":"","userId":"04237962560197153587"},"user_tz":-420},"id":"uywRnKfU-gpw","outputId":"676beb57-b1c7-4ddc-ed75-3013232813c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","epoch: 1 | Loss: 2.2105541646937885 | Train_acc: 22.5%| Test_acc: 25.0%\n","epoch: 2 | Loss: 1.4870719934058616 | Train_acc: 25.0%| Test_acc: 37.5%\n","epoch: 3 | Loss: 1.219945810487508 | Train_acc: 22.5%| Test_acc: 25.0%\n","epoch: 4 | Loss: 1.014613689668953 | Train_acc: 31.25%| Test_acc: 37.5%\n","epoch: 5 | Loss: 0.8829151498692115 | Train_acc: 36.25%| Test_acc: 37.5%\n","epoch: 6 | Loss: 0.8107481708611979 | Train_acc: 35.0%| Test_acc: 37.5%\n","epoch: 7 | Loss: 0.7438045533569267 | Train_acc: 38.75%| Test_acc: 31.25%\n","epoch: 8 | Loss: 0.6945394269950554 | Train_acc: 35.0%| Test_acc: 37.5%\n","epoch: 9 | Loss: 0.6572871023736646 | Train_acc: 46.25%| Test_acc: 62.5%\n","epoch: 10 | Loss: 0.6189485538341201 | Train_acc: 58.75%| Test_acc: 68.75%\n","epoch: 11 | Loss: 0.5943183991915125 | Train_acc: 51.25%| Test_acc: 62.5%\n","epoch: 12 | Loss: 0.5688743444964709 | Train_acc: 50.0%| Test_acc: 56.25%\n","epoch: 13 | Loss: 0.5478254115337606 | Train_acc: 61.25%| Test_acc: 68.75%\n","epoch: 14 | Loss: 0.5326534419718301 | Train_acc: 56.25%| Test_acc: 56.25%\n","epoch: 15 | Loss: 0.5163113178347077 | Train_acc: 65.0%| Test_acc: 62.5%\n","epoch: 16 | Loss: 0.49702552982303494 | Train_acc: 48.75%| Test_acc: 68.75%\n","epoch: 17 | Loss: 0.48749538440533613 | Train_acc: 70.0%| Test_acc: 62.5%\n","epoch: 18 | Loss: 0.47876894458785385 | Train_acc: 73.75%| Test_acc: 75.0%\n","epoch: 19 | Loss: 0.4636526035378351 | Train_acc: 67.5%| Test_acc: 62.5%\n","epoch: 20 | Loss: 0.4534002466274954 | Train_acc: 58.75%| Test_acc: 68.75%\n","==\u003e Learning Rate Descent\n","epoch: 21 | Loss: 0.3400155170570554 | Train_acc: 62.5%| Test_acc: 56.25%\n","epoch: 22 | Loss: 0.30869132619532175 | Train_acc: 71.25%| Test_acc: 62.5%\n","epoch: 23 | Loss: 0.2942223097281078 | Train_acc: 61.25%| Test_acc: 75.0%\n","epoch: 24 | Loss: 0.28622929245004874 | Train_acc: 76.25%| Test_acc: 56.25%\n","epoch: 25 | Loss: 0.2770239654976084 | Train_acc: 70.0%| Test_acc: 68.75%\n","epoch: 26 | Loss: 0.2707762155881928 | Train_acc: 62.5%| Test_acc: 81.25%\n","epoch: 27 | Loss: 0.26653086870451415 | Train_acc: 68.75%| Test_acc: 62.5%\n","epoch: 28 | Loss: 0.2616992062696106 | Train_acc: 66.25%| Test_acc: 56.25%\n","epoch: 29 | Loss: 0.25807068052956517 | Train_acc: 71.25%| Test_acc: 75.0%\n","epoch: 30 | Loss: 0.25194215738331266 | Train_acc: 75.0%| Test_acc: 68.75%\n","epoch: 31 | Loss: 0.2484811759170364 | Train_acc: 63.75%| Test_acc: 75.0%\n","epoch: 32 | Loss: 0.24202909356797747 | Train_acc: 72.5%| Test_acc: 62.5%\n","epoch: 33 | Loss: 0.23764486976749147 | Train_acc: 73.75%| Test_acc: 68.75%\n","epoch: 34 | Loss: 0.2311271640193432 | Train_acc: 63.75%| Test_acc: 68.75%\n","epoch: 35 | Loss: 0.22975073486109218 | Train_acc: 77.5%| Test_acc: 75.0%\n","epoch: 36 | Loss: 0.22705884674168608 | Train_acc: 72.5%| Test_acc: 68.75%\n","epoch: 37 | Loss: 0.2171326969057093 | Train_acc: 75.0%| Test_acc: 75.0%\n","epoch: 38 | Loss: 0.22114118560195883 | Train_acc: 78.75%| Test_acc: 68.75%\n","epoch: 39 | Loss: 0.2168930796596705 | Train_acc: 77.5%| Test_acc: 68.75%\n","epoch: 40 | Loss: 0.20966694406841113 | Train_acc: 72.5%| Test_acc: 62.5%\n","==\u003e Learning Rate Descent\n","epoch: 41 | Loss: 0.19599746032367887 | Train_acc: 75.0%| Test_acc: 62.5%\n","epoch: 42 | Loss: 0.19020702463129294 | Train_acc: 70.0%| Test_acc: 62.5%\n","epoch: 43 | Loss: 0.19154496462372564 | Train_acc: 71.25%| Test_acc: 68.75%\n","epoch: 44 | Loss: 0.1885507444629584 | Train_acc: 75.0%| Test_acc: 68.75%\n","epoch: 45 | Loss: 0.1901186830685724 | Train_acc: 73.75%| Test_acc: 62.5%\n","epoch: 46 | Loss: 0.1836302774241361 | Train_acc: 75.0%| Test_acc: 68.75%\n","epoch: 47 | Loss: 0.18777665960819215 | Train_acc: 70.0%| Test_acc: 68.75%\n","epoch: 48 | Loss: 0.18387672251752576 | Train_acc: 78.75%| Test_acc: 75.0%\n","epoch: 49 | Loss: 0.18271500352398515 | Train_acc: 76.25%| Test_acc: 62.5%\n","epoch: 50 | Loss: 0.18190995854375613 | Train_acc: 72.5%| Test_acc: 75.0%\n","==\u003e Learning Rate Desscent...\n","==\u003e Finished Training ...\n"]}],"source":["# RMSprop\n","!python main.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"fqamsUHVGPUx"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n","170499072it [00:02, 57801624.86it/s]                   \n","Extracting ../data/cifar-10-python.tar.gz to ../data\n","Files already downloaded and verified\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","epoch: 1 | Loss: 2.7806006980978926 | Train_acc: 25.0%| Test_acc: 25.0%\n","epoch: 2 | Loss: 1.5431107560082165 | Train_acc: 16.25%| Test_acc: 25.0%\n","epoch: 3 | Loss: 1.2492598493385803 | Train_acc: 21.25%| Test_acc: 31.25%\n","epoch: 4 | Loss: 1.0389478636519682 | Train_acc: 30.0%| Test_acc: 25.0%\n","epoch: 5 | Loss: 0.9166646387875842 | Train_acc: 26.25%| Test_acc: 31.25%\n","epoch: 6 | Loss: 0.8319346171510799 | Train_acc: 35.0%| Test_acc: 43.75%\n","epoch: 7 | Loss: 0.7665914275762066 | Train_acc: 38.75%| Test_acc: 50.0%\n","epoch: 8 | Loss: 0.7134315738897494 | Train_acc: 36.25%| Test_acc: 43.75%\n","epoch: 9 | Loss: 0.6725793169892352 | Train_acc: 42.5%| Test_acc: 43.75%\n","epoch: 10 | Loss: 0.6413553536243146 | Train_acc: 47.5%| Test_acc: 56.25%\n","epoch: 11 | Loss: 0.6110305821194368 | Train_acc: 47.5%| Test_acc: 56.25%\n","epoch: 12 | Loss: 0.5898970728335173 | Train_acc: 52.5%| Test_acc: 56.25%\n","epoch: 13 | Loss: 0.5650161589350542 | Train_acc: 38.75%| Test_acc: 56.25%\n","epoch: 14 | Loss: 0.5398472332588548 | Train_acc: 57.5%| Test_acc: 50.0%\n","epoch: 15 | Loss: 0.5258374524390911 | Train_acc: 47.5%| Test_acc: 56.25%\n","epoch: 16 | Loss: 0.5142852870552131 | Train_acc: 46.25%| Test_acc: 50.0%\n","epoch: 17 | Loss: 0.497238508118388 | Train_acc: 65.0%| Test_acc: 50.0%\n","epoch: 18 | Loss: 0.48730799860661594 | Train_acc: 51.25%| Test_acc: 62.5%\n","epoch: 19 | Loss: 0.4741457899665589 | Train_acc: 47.5%| Test_acc: 50.0%\n","epoch: 20 | Loss: 0.4639950589755612 | Train_acc: 65.0%| Test_acc: 68.75%\n","==\u003e Learning Rate Descent\n","epoch: 21 | Loss: 0.3507461733068042 | Train_acc: 68.75%| Test_acc: 50.0%\n","epoch: 22 | Loss: 0.31919403414211006 | Train_acc: 63.75%| Test_acc: 62.5%\n","epoch: 23 | Loss: 0.3063615535378761 | Train_acc: 56.25%| Test_acc: 62.5%\n","epoch: 24 | Loss: 0.29815819303093055 | Train_acc: 66.25%| Test_acc: 62.5%\n","epoch: 25 | Loss: 0.288546823841684 | Train_acc: 53.75%| Test_acc: 62.5%\n","epoch: 26 | Loss: 0.2792374195192781 | Train_acc: 52.5%| Test_acc: 68.75%\n","epoch: 27 | Loss: 0.27435309828623483 | Train_acc: 53.75%| Test_acc: 62.5%\n","epoch: 28 | Loss: 0.2711635763992739 | Train_acc: 63.75%| Test_acc: 62.5%\n","epoch: 29 | Loss: 0.2665703257217127 | Train_acc: 62.5%| Test_acc: 62.5%\n","epoch: 30 | Loss: 0.2592892055316349 | Train_acc: 61.25%| Test_acc: 68.75%\n","epoch: 31 | Loss: 0.25657598781006413 | Train_acc: 67.5%| Test_acc: 75.0%\n","epoch: 32 | Loss: 0.2511837748462892 | Train_acc: 66.25%| Test_acc: 62.5%\n","epoch: 33 | Loss: 0.24690472273646719 | Train_acc: 67.5%| Test_acc: 56.25%\n","epoch: 34 | Loss: 0.24132571283661192 | Train_acc: 65.0%| Test_acc: 56.25%\n","epoch: 35 | Loss: 0.2407430247272677 | Train_acc: 60.0%| Test_acc: 56.25%\n","epoch: 36 | Loss: 0.23220351561332297 | Train_acc: 71.25%| Test_acc: 56.25%\n","epoch: 37 | Loss: 0.22983850127138444 | Train_acc: 73.75%| Test_acc: 68.75%\n","epoch: 38 | Loss: 0.2283143679351758 | Train_acc: 68.75%| Test_acc: 68.75%\n","epoch: 39 | Loss: 0.2242535390436192 | Train_acc: 72.5%| Test_acc: 62.5%\n","epoch: 40 | Loss: 0.2159502020539225 | Train_acc: 73.75%| Test_acc: 56.25%\n","==\u003e Learning Rate Descent\n","epoch: 41 | Loss: 0.20078970377554978 | Train_acc: 75.0%| Test_acc: 56.25%\n","epoch: 42 | Loss: 0.1980331869953124 | Train_acc: 55.0%| Test_acc: 62.5%\n","epoch: 43 | Loss: 0.19777035448328614 | Train_acc: 61.25%| Test_acc: 56.25%\n","epoch: 44 | Loss: 0.1962114350532022 | Train_acc: 58.75%| Test_acc: 56.25%\n","epoch: 45 | Loss: 0.19584130188998053 | Train_acc: 71.25%| Test_acc: 56.25%\n","epoch: 46 | Loss: 0.19612175292904724 | Train_acc: 81.25%| Test_acc: 56.25%\n","epoch: 47 | Loss: 0.19373703275418952 | Train_acc: 71.25%| Test_acc: 56.25%\n","epoch: 48 | Loss: 0.1953148101373097 | Train_acc: 68.75%| Test_acc: 62.5%\n","epoch: 49 | Loss: 0.19122092641146896 | Train_acc: 75.0%| Test_acc: 62.5%\n","epoch: 50 | Loss: 0.19131259103793927 | Train_acc: 67.5%| Test_acc: 56.25%\n","==\u003e Learning Rate Desscent...\n","==\u003e Finished Training ...\n"]}],"source":["# RMSprop + new preprocessing\n","!python main.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_cefGghd82gH"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mP5mZyTj9SG8"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"efTaJPoo8_s_"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPKgLdQBENSWENyMhqZQwcs","name":"CIFAR10v2.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}